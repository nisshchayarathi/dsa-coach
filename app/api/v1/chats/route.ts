import { NextResponse } from "next/server";
import { getServerSession } from "next-auth";
import { authOptions } from "@/lib/auth/auth";
import { GoogleGenerativeAI } from "@google/generative-ai";
import { GoogleGenerativeAIEmbeddings } from "@langchain/google-genai";
import { Pinecone } from "@pinecone-database/pinecone";
import { GoogleGenAI } from "@google/genai";

interface ChatHistory {
  role: string;
  parts: any;
}

const ai = new GoogleGenAI({});

const embeddings = new GoogleGenerativeAIEmbeddings({
  apiKey: process.env.GEMINI_API_KEY!,
  model: "text-embedding-004",
});

const pinecone = new Pinecone({
  apiKey: process.env.PINECONE_API_KEY!,
});
const pineconeIndex = pinecone.Index(process.env.PINECONE_INDEX_NAME!);

// helper
async function withRetry<T>(
  fn: () => Promise<T>,
  maxRetries = 3,
  delayMs = 1000
): Promise<T> {
  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    try {
      return await fn();
    } catch (error: any) {
      if (error.status === 503 && attempt < maxRetries) {
        console.warn(`Attempt ${attempt} failed. Retrying in ${delayMs}ms...`);
        await new Promise((resolve) => setTimeout(resolve, delayMs));
        delayMs *= 2;
      } else {
        throw error;
      }
    }
  }
  throw new Error("Max retries reached without success"); // ‚úÖ ensures return
}

export async function POST(req: Request) {
  console.log("ü§ñ Chat API called");

  // Check session (but don't block if no session - allow anonymous usage)
  const session = await getServerSession(authOptions);
  console.log(
    "üë§ Session status:",
    session
      ? `Logged in as ${session.user?.email} (${(session.user as any)?.role})`
      : "No session (anonymous)"
  );

  try {
    const { question, history } = await req.json();
    console.log("üìù Question received:", question);
    console.log("üìö History length:", history || 0);

    const formattedHistory: ChatHistory[] = (history || []).filter(
      (msg: any) =>
        msg &&
        msg.role &&
        Array.isArray(msg.parts) &&
        msg.parts.length > 0 &&
        msg.parts[0].text
    );

    formattedHistory.push({
      role: "user",
      parts: [{ text: question }],
    });

    // Remove the first message if it's the initial bot greeting
    if (formattedHistory.length > 0 && formattedHistory[0].role === "model") {
      formattedHistory.shift();
    }

    ////////////////////
    const userHistory = formattedHistory
      .filter((msg) => msg.role === "user")
      .map((msg) => msg.parts[0].text); // extract text

    const followUpQuestion = userHistory.pop(); // last user input

    console.log("üîÆ Generating Enhanced Question...");
    const enhancedQuestion = await ai.models.generateContent({
      model: "gemini-2.5-flash",
      contents: [
        {
          role: "user",
          parts: [
            {
              text: `Previous user messages:\n${userHistory.join(
                "\n"
              )}\nFollow-up question: ${followUpQuestion}`,
            },
          ],
        },
      ],
      config: {
        systemInstruction: `You are a query rewriting expert. Rephrase the Follow-up question into a standalone question. Only output the rewritten question, no explanations.`,
      },
    });

    formattedHistory.pop();
    formattedHistory.push({
      role: "user",
      parts: [{ text: enhancedQuestion.text || question }],
    });

    // embed question
    console.log(enhancedQuestion.text);
    const queryVector = await embeddings.embedQuery(
      enhancedQuestion.text || "Could not generate question"
    );

    // search Pinecone
    const searchResults = await pineconeIndex.query({
      topK: 10,
      vector: queryVector,
      includeMetadata: true,
    });

    const context = searchResults.matches
      .map((m) => String(m.metadata?.text ?? "")) // safe string
      .filter((t) => t.trim().length > 0)
      .join("\n\n---\n\n");

    // system instruction
    const systemInstruction = `You are a Data Structures and Algorithms expert AI assistant. 
Answer all user questions in a **clear, concise, and chat-friendly way**. 

Follow these rules for every response:

1. Start with a short one-line definition or explanation.
2. Break down key points using bullet points (2‚Äì5 bullets max).
3. Avoid dense paragraphs; keep sentences short and readable.
4. Use simple terms and examples where appropriate.
5. If the user asks a follow-up, continue from the previous answer, 
   assuming they already know what was explained before. Do not repeat the entire previous explanation.
6. If the answer is not available in the provided context, respond with: 
   "I cannot find any information about this related to DSA, please explain me again."

Always make the response suitable for chat display.
    Context: ${context}`;

    console.log(
      "üß© formattedHistory:",
      JSON.stringify(formattedHistory, null, 2)
    );

    // generate response
    console.log("üîÆ Generating AI response...");
    const response = await ai.models.generateContent({
      model: "gemini-2.5-flash",
      contents: formattedHistory,
      config: {
        systemInstruction,
      },
    });

    console.log("üéØ Raw AI response received:", response);
    const answer = response.text;

    // If empty response, provide a fallback
    if (!answer || answer.trim().length === 0) {
      console.log("‚ö†Ô∏è Empty response detected, using fallback");
      const fallbackAnswer = "I understand you're asking about dsa.";
      return NextResponse.json({
        answer: fallbackAnswer,
        fallback: true,
      });
    }

    console.log("‚úÖ Successfully generated response, length:", answer.length);
    console.log(
      "üìÑ Response content preview:",
      answer.substring(0, 100) + "..."
    );

    return NextResponse.json({
      answer,
    });
  } catch (error: any) {
    console.error("‚ùå Chat API error:", error);
    console.error("Error details:", error.message, error.status);
    console.error("Full error object:", JSON.stringify(error, null, 2));

    // Check if it's an API key or service issue
    if (error.message?.includes("API key") || error.status === 403) {
      console.error("üîë API Key issue detected");
      return NextResponse.json(
        {
          error: "Configuration issue with AI service",
          details: "API key problem",
        },
        { status: 500 }
      );
    }

    if (error.message?.includes("quota") || error.status === 429) {
      console.error("üìä Quota exceeded");
      return NextResponse.json(
        {
          error: "Service temporarily unavailable due to quota limits",
          details: "Try again later",
        },
        { status: 503 }
      );
    }

    // Return more detailed error information
    return NextResponse.json(
      {
        error: "Chat service temporarily unavailable",
        details: error.message || "Unknown error",
        errorType: error.constructor.name,
      },
      { status: 500 }
    );
  }
}
